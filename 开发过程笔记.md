# 开发过程笔记

## Lab1

综述：实现读取分页二进制文件转换为数据表，数据表含多个页面，每个页面含多行(tuple)，并实现对数据表的顺序遍历。

### Exercise1

#### 任务要求

阅读文档 `lab1.md` 可知，需要完成 `storage` 包的 `Tuple.java` 和 `TupleDesc.java` 两个类的补充编写，通过 `TupleTest` 和 `TupleDescTest`。

阅读源码，根据相关知识推断，`TupleDesc` 是一张数据表的各列的声明(description)，其中，要手写的数据库支持两种数据类型(参见 `common.Type` 枚举类)，其中 `INT_TYPE` 长度为 $4$ 位，定长字符串类 `STRING_TYPE` 长为 $128+4$ 位，恒只有 $128$ 个字符。这两种数据类型的父类是 `common.Field`，子类是 `IntField` 和 `StringField`。基本的方法已经写好，包括比较、构造、取值等。且 `TupleDesc` 有一个静态内部类 `TDItem`，有 `Type fieldType` 和 `String fieldName` 两个属性。

`TupleDesc` 未实现的方法有：

- 构造函数 `public TupleDesc(Type[] typeAr, String[] fieldAr)`

  `public TupleDesc(Type[] typeAr)`

- 取字段数 `public int numFields()`

- 取各字段迭代器 ` public Iterator<TDItem> iterator()`

- 取特定字段 `public String getFieldName(int i) throws NoSuchElementException`

  `public Type getFieldType(int i) throws NoSuchElementException`

- 取字段下标 `public int indexForFieldName(String name) throws NoSuchElementException`。注意传 null 要 throw。如果字段未命名要 throw。

- 取大小 `public int getSize()` (bytes) 即各字段的大小之和

- 合并字段 `public static TupleDesc merge(TupleDesc td1, TupleDesc td2)`，直接有序拼接

- 判断相等 `public boolean equals(Object o)`

- 与 null / object 不等；自己与自己相等，字段同样相等

- 输出 `public String toString()`

阅读 `TupleDescTest` 单元测试类，核实需要做的功能：

- `public void getType()` 检查每个字段是否正确，支持 1000 个字段，下同
- `public void nameToId()` 检查每个字段命名是否正确
- `public void getSize()` 
- `ublic void numFields()`
- `public void testEquals()`
- `public void combine()`

`RecordId` 是一个未实现类。暂时按下不表。`Tuple` 是对应数据库的一行，维护表头描述和具体值。

`Tuple` 未实现的方法有：

- 构造函数 `public Tuple(TupleDesc td)`

- 取字段描述 `public TupleDesc getTupleDesc()`

- 取该表在磁盘的记录号 `public RecordId getRecordId()`

- 设置特定字段 `public void setField(int i, Field f)`

  `public Field getField(int i)`

- `public String toString() `

- 取所有值 `public Iterator<Field> fields()`

- 重新设置 `public void resetTupleDesc(TupleDesc td)`

`TupleTest` 单元测试要完成的功能：

- `public void modifyFields()`
- `public void getTupleDesc()`
- `public void modifyRecordId()` (暂时不管)

#### 具体实现

##### TupleDesc

考虑到 `TupleDesc` 的少修改性质，使用直接的 `ArrayList` 或静态数组能达成 $O(1)$ 的询问，所以直接用其小模拟上述的 CRUD 即可。考虑到方便性，且 `ArrayList` 与静态数组的性能常数差别不大，这里考虑使用 `ArrayList`。

考虑到可能频繁的查询需求，这里对判断相等、根据列名取下标进行了预处理(使用了哈希表)，以多一倍的空间代价换取了高效的时间代价。具体而言，除了构造函数、合并(`combine`)和输出(`toString`)外，所有其他 `TupleDesc` 的函数实现，即：`numFields, iterator, getFiledName, getFieldType, indexForFieldName, getSize, equals` 函数都完成了 $O(1)$ 的实现。

使用的内部成员变量为：

```java
private ArrayList<TDItem> items;
private int size; // 预处理
private int hashCode; // 预处理
private HashMap<String, Integer> name2index; // 预处理
```

特别地，为 `TDItem` 类新增了 `hashCode` 方法，以支持 $O(1)$ 的 equals 实现。具体哈希函数为：

```java
@Override
public int hashCode() {
    if (fieldName == null) {
        return 0;
    }
    return fieldName.hashCode() * (fieldType == Type.INT_TYPE ? 7 : 11);
}
```

其中 7 和 11 是两个质数，能比较好地减少冲突。如果后续还需要反复对 `Type` 类求冲突，则将考虑会把 `hashCode` 函数写到 `Type` 去。

综上所述，`TableDesc` 本质上还是一个简单朴素的 CRUD 小模拟，很好实现。详见源码。

##### Tuple

不考虑 `RecordId`，那么剩下的事情就是同理，加成员属性：

```c++
private TupleDesc tupleDesc;
private ArrayList<Field> fields;
```

实现对其的初始化和查询修改即可。

> 对于代码注释给定的 `only affecting the TupleDesc`，我个人的理解是只需要修改 `tupleDesc` 而不用管 `fields`，我暂时没看到 `resetTupleDesc` 在单元测试出现，所以不知道它具体会用来干嘛，如果以后这里出错了，再修改一下，改成把 `fields` 也重新刷新一遍即可。



### Exercise2

#### 任务要求

`common.Database` 是一个饿汉单例模式，拥有一个 `common.Catalog _catalog` 和其他内容(后续再说)。`DbFile` 是一个接口，表示一个磁盘的数据库文件。

> 具体而言，`DbFile` 接口提供的方法如下：
>
> - `TupleDesc getTupleDesc()`
>
> - `int getId()` 唯一标识 `HeapFile` 的 ID
>
> - `DbFileIterator iterator(TransactionId tid)` 
>
>   其中 `DbFileIterator` 是遍历所有 `Tuple` 的迭代器，有 `open(), hasNext(), next(), rewind(), close()` 方法
>
>   `TransactionId` 标识事务 ID，其 ID 通过静态类原子计数器自增，即每次构造函数得到唯一自增的整数 long 作为事务 ID，通过 `public long getId()` 取出
>
> - `Page readPage(PageId id)` 读取磁盘的一页
>
>   其中 `PageId` 是接口，有 `int getTableId()`, `int getPageNumber()` 等方法
>
>   `Page` 是接口，有 `PageId getId()`, `byte[] getPageData()` 等方法
>
> - `void writePage(Page p)`
>
> - `List<Page> insertTuple(TransactionId tid, Tuple t)`
>
> - `List<Page> deleteTuple(TransactionId tid, Tuple t)`

`Catalog` 支持的方法：

- 构造函数 `public Catalog()`

- 添加数据表 `public void addTable(DbFile file, String name, String pkeyField)` (第三个参数是主键名字)

  `public void addTable(DbFile file, String name)`

  `public void addTable(DbFile file)`

  name 不能 null，可以空串；冲突时覆盖被冲突者

- 取数据表 `public int getTableId(String name) throws NoSuchElementException`，其中 table id 是随机的(不是 auto increment)，注意判 null。重复 table name 但不同 table id 可以允许

  `public TupleDesc getTupleDesc(int tableid) throws NoSuchElementException`

  `public DbFile getDatabaseFile(int tableid) throws NoSuchElementException`

  `public String getPrimaryKey(int tableid)`

- 取数据表id遍历器 `public Iterator<Integer> tableIdIterator()`

- 清空 `public void clear()`

单元测试 `CatalogTest` 要完成的任务：

- 新建两表格 `@Before public void addTables()` 
- `public void getTupleDesc()` 
- `public void getTableId()`
- `public void getDatabaseFile()`
- `public void handleDuplicateNames()` 重复 table name 但不同 table id 可以允许，新 id 覆盖旧 id。
- `public void handleDuplicateIds()` 重复 table id 不同 table name 可以允许，新 name 覆盖旧 name

#### 具体实现

考虑用 name 或 id 作键，`DBFile` 做值的 `HashSet`，能够满足功能需求，也符合实际含义。且 `DBFile` 能导出要求的 `TupleDesc`。考虑迭代器需求，用 id 作键，像 `TDItem` 一样做一个 name, 主键和 `DBFile` 三元组，且反向再用 name 做键对 id。对冲突讨论：

1. 新增重复 name 不同 id，会修改反向 `HashSet`，但通过 id 仍能找到旧表，所以要手动删掉旧表
2. 新增重复 id 不同 name，直接修改 `HashSet`，但反向能找到旧的无效 id，所以要手动删掉旧表
3. 新增重复 name 重复 id，两边都删。

总结逻辑为：先删重复 id 和重复 name，之后再插入。

新增的内部类为：

```java
public static class TableItem implements Serializable {
    public final DbFile dbFile;
    public final String name;
    public final String primaryKey;
}
```

新增的成员变量为：

```java
private HashMap<Integer, TableItem> tables;
private HashMap<String, Integer> name2tableId;
```

同理，空间换时间，增加一点(不是一倍，`TupleDesc` 同理，两个 map 显然空间不一样)的空间，换取更优的时间效率，但是维护修改的代价也有所增大。所有方法(除构造函数和 clear 外)理论上都是 $O(1)$ 实现，即 `addTable, getTableId, tableIdIterator, getTupleDesc, getDatabaseFile, getPrimaryKey`。



### Exercise3

#### 任务要求

`Database` 单例有 `storage.BufferPool _bufferpool`，用于缓存从外存读到内存的页面。在这次练习需要完成构造函数和 `getPage()` 方法。最多存储 `numPages` 页，如果超了就用置换算法换掉(后续任务实现)。`flush_all_pages()` 是一个测试用方法，不能在正式代码使用。在日后的 `HeapFile` 测试才会测试该 `Exercise` 的内容。

`BufferPool` 仍要实现的方法：

- `public BufferPool(int numPages)` 创建给定页面数上限的缓存池

- `public Page getPage(TransactionId tid, PageId pid, Permissions perm) throws TransactionAbortedException, DbException`

  读取特定页面，具体逻辑：如果已经存在直接返回，否则如果空间未满，加入并返回，否则，置换加入并返回。

  其中 `Permissions` 是枚举类，有 `READ_ONLY`，`READ_WRITE` 两种权限。

> 其他在后续练习中才需要做的方法：
>
> - `public void unsafeReleasePage(TransactionId tid, PageId pid)`
> - `public void transactionComplete(TransactionId tid)`
> - `public boolean holdsLock(TransactionId tid, PageId p)`
> - `public void transactionComplete(TransactionId tid, boolean commit)`
> - `public void insertTuple(TransactionId tid, int tableId, Tuple t) throws DbException, IOException, TransactionAbortedException `
> - `public void deleteTuple(TransactionId tid, Tuple t) throws DbException, IOException, TransactionAbortedException `
> - `public synchronized void flushAllPages() throws IOException`
> - `public synchronized void removePage(PageId pid)`
> - `private synchronized void flushPage(PageId pid) throws IOException`
> - `public synchronized void flushPages(TransactionId tid) throws IOException`
> - `private synchronized void evictPage() throws DbException`

#### 具体实现

因为没有考虑未实现的功能，如锁、权限、事务，只考虑对最基本有限页面的管理和置换，所以后期可能需要重构该类。

由于我本人做 `Exercise 3` 时是暂时跳过的，先做了 `Exercise 4` 再倒回来做的，所以这里从下一个 `Exercise` 可以知道，`Page` 接口(下面具体为 `HeapPage` 类)的实现类存储了一个页面的全部信息，构造一个 `Page` 实现类需要传入 `byte[] data`，即首先需要读取文件，要知道文件的路径。

根据上文可知，`Catalog` 类实现了 table id 取 `DbFile`，其中 `DbFile` 含有磁盘文件路径 `File` 对象。所以实现了读取 Page。

由于只有最大 50 个页面，阅读 `Database` 类可知，不再会修改页面数，所以置换算法的时间复杂度要求不高。考虑使用 LRU 置换算法，鉴于只有 50 个页面，直接开一个维护各页面最大访问时间的 map 即可，然后每次暴力枚举所有页面的访问时间，把最小的页面扬了。

具体而言，开一个 `static final AtomicLong` 维护当前抽象时间，每次访问一个页面时间+1。然后维护支持并发的 map (`ConcurrentHashMap`)，记录每个页面 ID 的访问时间。同理，用并发 map 维护页面 ID 与页面的映射。

注意到可能并发访问，缺页时需要同步 synchronized 一下，避免反复读缺少的页。

增设内部辅助类：(可能后续会改)

```java
public static class LRUStrategy {
    static final AtomicLong nowcnt = new AtomicLong(0);
    public long getNow() {
        return nowcnt.getAndIncrement();
    }
    final ConcurrentHashMap<PageId, Long> lastCnt = new ConcurrentHashMap<>();
    public void visitPage(PageId pageId) {
        lastCnt.put(pageId, getNow());
    }
    public PageId getLruPageId() {
        PageId minPage = null;
        Long minCnt = Long.MAX_VALUE;
        for (Map.Entry<PageId, Long> pair : lastCnt.entrySet()) {
            Long cnt = pair.getValue();
            if (cnt < minCnt) {
                minCnt = cnt;
                minPage = pair.getKey();
            }
        }
        assert minPage != null;
        return minPage;
    }
    public void removePage(PageId pageId) {
        lastCnt.remove(pageId);
    }
}
```

增设成员：

```java
private final int numPages;
private final ConcurrentHashMap<PageId, Page> pages;
private final LRUStrategy lru;
```

则核心逻辑为：(可能后续会改)

```java
public Page getPage(TransactionId tid, PageId pid, Permissions perm)
    throws TransactionAbortedException, DbException {
    // DONE: some code goes here
    Page page = pages.get(pid);
    if (page == null) {
        synchronized (this) {
            DbFile file = Database.getCatalog().getDatabaseFile(pid.getTableId());
            page = file.readPage(pid);
            while (pages.size() >= numPages) {
                evictPage();
            }
            pages.put(pid, page);
            lru.visitPage(pid);
        }
    }
    return page;
}
```





### Exercise4

#### 任务要求

从磁盘读写数据的文件包括 heap files(tuples 的无序组合)和 B 树。

一个 `storage.HeapFile` 包含一些页面，每个页面有固定数量的字节(`BufferPool.DEFAULT_PAGE_SIZE=4096`bytes，含头部)。一个 slot 槽可以容纳一个 tuple 元组。头部包含 bitmap，每一位表示一个槽，若位值为 1，则该 tuple 有效，为 0 无效(删掉或未初始化)。具体的 `Page` 实现类是 `HeapPage`。这些 page 存在 `BufferPool`，被 `HeapFile` 读写。

每个 tuple 有 1 位头部，大小为 $8|tuple\_size|+1$ 位，故每页能存 $n=\lfloor\dfrac{8|page\_size|}{8|tuple\_size|+1}\rfloor$ 个 tuple。头部占用字节数显然为 $\lceil\dfrac n8\rceil$。LSB(least significant/low bit)标识 slot 的状态，即第一个 slot 是否有效，以此类推。而 JVM 是大端存储的，即如0x1234数据和两个地址0x1,0x2，0x1存0x12, 0x2存0x34，所以一个数组，按顺序读就行，不用倒序读。无效 slot 就全 0 位占对应的 tuple。整个结构是：头部(01数组)+按顺序各tuple。

`storage.HeapPageId` 是 `PageId` 接口实现类，需要完成：

- `public HeapPageId(int tableId, int pgNo)`
- `public int getTableId()`
- `public int getPageNumber()`
- `public int hashCode()`
- `public boolean equals(Object o)`

有单元测试 `HeapPageIdTest`，很简单，不细说。

`storage.RecordId` 表示特定 table 的特定 page 的一个 tuple。有需要完成的：

- `public RecordId(PageId pid, int tupleno)` (即 slot id)
- `public int getTupleNumber()`
- `public PageId getPageId()`
- `public int hashCode()`
- `public boolean equals(Object o)`

有单元测试 `RecordId`，很简单，不细说。

`storage.HeapPage` 存储一页的数据，并存储在 `BufferPool`，实现了 `Page` 接口。构造函数已经写好框架，具体子函数有需要补充的，功能是将字节流转为具体数据。需要完成：

- `private int getNumTuples()` 通过上述公式计算
- `private int getHeaderSize()` 通过上述公式计算
- `public HeapPageId getId()` 
- `public int getNumUnusedSlots()`
- `public boolean isSlotUsed(int i)`
- `public Iterator<Tuple> iterator()`

> 以后要做的：
>
> - `public void deleteTuple(Tuple t) throws DbException`
> - `public void insertTuple(Tuple t) throws DbException`
> - `public void markDirty(boolean dirty, TransactionId tid)`
> - `public TransactionId isDirty()`
> - `private void markSlotUsed(int i, boolean value)`

需要通过 `HeapPageReadTest` 单元测试，具体为对上述函数的基本测试。

#### 具体实现

`HeapPageId` 感觉是纯纯的 POJO，直接存 `private final int tableId, pgNo` 即可。哈希值使用了质数 $100007tableId+pgNo$。`equals` 仿照 `transaction.TransactionId` 依葫芦画瓢。

同理，`RecordId` 也是 POJO，直接存即可，哈希这里用了 $100003hash(pid)+tupleNo$。其他画瓢即可。

对 `HeapPage`，根据上文公式(整数上下取整即可，不需要用 Math 类)求出要求的页数等。注意到 header 本身就是 slot 的压位存储，byte 是 0-255 的整数。所以求 0 的个数即可统计未用 slots 数。那么就很简单了。对 slot 号对应 header 位，即第 $\lfloor\dfrac {slot}8\rfloor$ 个 byte 数组元素的第 $slot\bmod 8$ 低位。

注意到 iterator 注释里要求需要跳过空的 slots，所以遍历一下去重，重构一下 tuples 为 `ArrayList` 即可。



### Exercise5

#### 任务要求

从磁盘读取一页，需要计算文件偏移量，读取时不能调用 `BufferPool`。

`storage.HeapFile` 的 iterator 方法遍历所有元组，必须使用 `BufferPool.getPage`。打开文件时不能把整个数据表载入内存。

`HeapFile` 实现了 `DBFile` 接口，应包含一系列 `Page`。要实现：

- `public HeapFile(File f, TupleDesc td)`
- `public File getFile()`
- `public int getId()` 需要管理生成唯一的 table id 并返回，可以通过对文件绝对路径做哈希生成
- `public TupleDesc getTupleDesc()`
- `public Page readPage(PageId pid)` 从磁盘读取一页
- `public int numPages()`
- `public DbFileIterator iterator(TransactionId tid)`

具体而言，`DbFileIterator` 需要支持：

- `void open() throws DbException, TransactionAbortedException`
- `boolean hasNext() throws DbException, TransactionAbortedException`
- `Tuple next() throws DbException, TransactionAbortedException, NoSuchElementException`
- `void rewind() throws DbException, TransactionAbortedException`
- `void close()`

> 暂时不需要实现的方法：
>
> - `public void writePage(Page page) throws IOException`
> - `public List<Page> insertTuple(TransactionId tid, Tuple t) throws DbException, IOException, TransactionAbortedException`
> - `public List<Page> deleteTuple(TransactionId tid, Tuple t) throws DbException, TransactionAbortedException`

需要通过的单元测试为 `HeapFileReadTest`，除去基本显然的外，部分具体为：

- `public void readPage()` 读取文件的第一页 ID 存储为 `HeapPageId`，然后根据其调用 `readPage`
- `public void testIteratorBasic()` 得到 iterator it 后，在未调用 `it.open()` 时不可以调用 `next()`(预期抛出异常)，且 `hasNext()` 是 false；open 后，要求元组数目正确，各元组不为 null。
- `public void testIteratorClose()` 在 open 且 close 后，应当调用 `next()` 抛出异常



#### 具体实现

对 `File, TupleDesc` 显然要存储，比较简单。对 ID 的处理，根据提示直接使用 `f.getAbsoluteFile().hashCode()` 即可。重点是 `Page` 相关的全部处理。

根据文件格式的定义，文件是二进制文本、每 page 各自拥有含义，可以知道页数为文件的字节数除以页大小(上取整)。

读取 page，使用 `RandomAccessFile` 打开 File，然后用 seek 跳转起止位置，并逐字符读取即可，读完 data 交给 `HeapPage` 去构造。

对迭代器，如果当前 iterator 为空或没下一个元素了，调用 `BufferPool` 读下一个 page 一次读入若干 tuple，如果调用后还是为空或没下一个元素就 `hasNext` 为假。如果不为假就可以 `next()`。然后注意特判没 `open` 算没 `hasNext`。而 `rewind` 就重新构造即可，`open` 就先设内部状态为已打开再调用 rewind，close 就清掉内部状态。

可以使用匿名内部类，然后事务 ID 是给用来调用 `BufferPool` 的读 page 用的，可以存私有也可以不存。核心 `hasNext` 逻辑是：

```java
if (!opened) {
    return false;
}
if (it == null || !it.hasNext()) {
    readPage(); //最后一页就it=null,否则it=HeapPage.iterator且nowPageNo++
    if (it == null || !it.hasNext()) {
        return false;
    }
}
return true;
```



### Exercise6

#### 任务要求

Operator 操作符负责执行数据库查询。有 `execution.SeqScan` 操作符，顺序遍历给定 table 的所有 tuple。该类实现了 `OpIterator` 接口，该接口与 `DbFileIterator` 十分接近，但是多了一个新的方法 `TupleDesc getTupleDesc()`。

对 `SeqScan`，未实现方法有：

- `public SeqScan(TransactionId tid, int tableid, String tableAlias)` 其中 alias 是 catalog 里存的数据库名字或特别指定(如 SQL 的 as)
- `public String getAlias()`
- `public void reset(int tableid, String tableAlias)`
- `public void open()`
- `public TupleDesc getTupleDesc()`
- `public boolean hasNext()`
- `public Tuple next()`
- `public void close()`
- `public void rewind()`

需要通过 `ScanTest` 系统测试，有：

- `public void testSmall()` 随机生成 8096 行内，4列内的数据表，要求不重不漏地扫描所有项
- `public void testRewind()` 读 100 项然后迭代器归零重读
- `public void testCache()` scan 两次同一个 table，对只有一列的 int，一页有 992 个 tuple，具体而言占用 4092 个 byte 且 993 要占用 4097 故只能 992；期望第一次读时读取到全部页数进缓存(具体而言是 buffer pool 的 50 页大小)，第二次遍历全部时 `readPage` 不正常返回(置换算法如 LRU 大概能保证存进去的不跑走)
- `public void testTupleDesc()` 检查数据表名、列名一致。注意如果 `SeqScan` 的前缀为 `prefix`，则 `TableDesc` 的列名应当为 `prefix.列名`，所以要重构 `TupleDesc`

#### 具体实现

具体迭代(`open, next, close, rewind, hasNext`)就直接调用上一个 exercise 写好的迭代器即可。

对 `TupleDesc`，重新构造一个，把所有 field name 加上前缀 `alias.`。整体而言是比较简单的一个任务。

### 应用测试

如果有一个 2 行 3 列的数据表纯文本 `lab1test.txt` 放在项目根目录：(注意加空行)

```
5,8,0
2,3,3

```

对 `common.SimpleDb.java` 类，根据主函数描述，可以在 ecplise 里点 run as 加参数 `convert lab1test.txt 3`(3代表3列)，然后运行结束发现同目录下出现了 `lab1test.dat`。

参照 `lab1.md` 接下来写一个测试类 `test/simpledb.mytest.Test1` (具体见代码)并运行，来测试整个 `Lab1`，读取一整个文件并输出。



## Lab2

### Exercise1

#### 任务要求

`common.OpIterator` 是关系代数的运算操作。需要实现下面两种运算：

`execution.Filter` 是过滤出满足特定条件的全部 tuples。其中需要使用到 `execution.Predicate` 类，即比较谓词，其内部有一个枚举类 `Op`，具有 `==,<,>,<=,>=,like,!=` 七种枚举值。

`Predicate` 需要完成的功能有：

- `public Predicate(int field, Op op, Field operand)` 传入比较右值(int是表示tuple的第几列)
- `public int getField()`
- `public Op getOp()`
- `public Field getOperand()`
- `public boolean filter(Tuple t)` 传入左值
- `public String toString()`

需要通过 `PredicateTest` 单元测试，包含对整数的 5 种比较。

对 `Filter` 类，实现了 `execution.Operator` 接口，需要完成的功能为：

- `public Filter(Predicate p, OpIterator child)`
- `public Predicate getPredicate()`
- `public TupleDesc getTupleDesc()`
- `public void open()`
- `public void close()`
- `public void rewind()`
- `protected Tuple fetchNext() throws NoSuchElementException, TransactionAbortedException, DbException`
- `public OpIterator[] getChildren()`
- `public void setChildren(OpIterator[] children)`

`Operator` 是抽象类，有成员 `Tuple next`, `boolean open`, `int estimatedCardinality`。实现了 `open()`(改 open 为 true)，`close()`(该 false, 且 next 置 null)，有 card 的 getter, setter，实现了 `hasNext()` 主要是判 open 和 next 是否空且尝试获取(`fetchNext()`)后还未空，实现了 `next()` 若 next 空 `fetchNext()`，仍空就 throw，否则返回 next 并设为 next=null。

`Operator` 有几个抽象方法需要实现：

- `protected abstract Tuple fetchNext() throws DbException, TransactionAbortedException`
- `public abstract OpIterator[] getChildren()`
- `public abstract void setChildren(OpIterator[] children)`
- `public abstract TupleDesc getTupleDesc()`

> 作为参考，项目已经实现了 `OrderBy` 操作和 `Project` 操作。
>
> 以 `OrderBy` 为例，open 时对传入的 `OpIterator child`，遍历它的全部 `Tuple` 并存 `ArrayList` 然后排序，得到排序后的迭代器，后续 `fetchNext` 就用它的迭代器即可。而这个操作的 `getChildren` 就返回 `{child}` 即可，set 同理 `child=children[0]`。
>
> 对 `Project`，即取列的子集操作，`fieldList` 表示要取的列数，重构 `TupleDesc`，每次 next 时对 `child` 的 tuple 重构并返回。

对 `FliterTest` 单元测试，没啥特别好说的。

需要完成的另一个操作符是 `Join`，依赖于 `JoinPredicate`，都在 `execution` 包。其中 `JoinPredicate` 类复用 `Predicate` 类的内部类 `Op`。

`JoinPredicate` 类需要完成的方法有：

- `public JoinPredicate(int field1, Predicate.Op op, int field2)` 分别是左值、操作符、右值
- `public int getField1()`
- `public int getField2()`
- `public Predicate.Op getOperator()`
- `public boolean filter(Tuple t1, Tuple t2)` 比较第 field1 个字段和第 field2 个字段

需要通过 `JoinPredicateTest` 单元测试，内容与 `PredicateTest` 类似。

`Join` 实现 `Operator` 接口，需要完成：

- `public Join(JoinPredicate p, OpIterator child1, OpIterator child2)`
- `public JoinPredicate getJoinPredicate()`
- `public String getJoinField1Name()`
- `public String getJoinField2Name()`
- `public TupleDesc getTupleDesc()`
- `public void open()`
- `public void close()`
- `public void rewind()`
- `protected Tuple fetchNext()`
- `public OpIterator[] getChildren()`
- `public void setChildren(OpIterator[] children)`

需要通过 `JoinTest` 单元测试，具体结果预期跟 SQL 的 join where 差不多。

最后通过同名系统测试 `FilterTest` 和 `JoinTest`。

#### 具体实现

对 `Predicate`，按照要求，复用 `Field` 具体实现类的 `compareTo` 即可，具体为抽取 t 的第 field 个 Field 调用它的 `compareTo` 传入 op, operand。

对 `Filter`，模仿 `Project`，可以完成大部分操作如 `open, close, rewind` 和 children 相关的。对 `fetchNext`，就 while 取下一个直到符合谓词才返回即可。

对 `JoinPredicate`，类比 `Predicate` 容易实现。

对 `Join`，即 SQL 的 join 操作，条件是 where + `Joinpredicate`。由于 next 的特性，导致每个 tuple 只能访问一次，所以对每个左表行，必须缓存下所有匹配的右表行，可以用一个 queue 实现。

### Exercise2

#### 任务要求

聚合语句 group by，只需要完成对单一列的聚合操作，使用 `executor.Aggregator` 接口，该接口有常量 `int NO_GROUPING = -1`，有枚举类 `Op`，提供以下几种聚合操作：`MIN, MAX, SUM, AVG, COUNT, SUM_COUNT, SC_VG`，且 `Op` 类提供方法 `getOp(int i)` 等。接口需要实现：

- `void mergeTupleIntoGroup(Tuple tup)`
- `OpIterator iterator()`

有具体实现类 `executor.IntegerAggregator`，需要实现：

- `public IntegerAggregator(int gbfield, Type gbfieldtype, int afield, Op what)` 等待被 group by 操作保留的列号及其类型；进行聚合运算和存放聚合结果的列号及其聚合操作。如果 `gbfield` 是接口常量 `NO_GROUPING`，只返回结果列，否则多返回一个键列(参考 SQL 一般的 group by)
- ` public void mergeTupleIntoGroup(Tuple tup)` 新合并一列，更新聚合结果
- `public OpIterator iterator()` 遍历聚合结果，返回 pair `groupVal, aggregateVal` 或单列 `aggregateVal`，取决于 `gdfield` 是不是  `NO_GROUPING`。随时可以取迭代器，而不是算完才取，每个迭代器相互独立，故不能缓存单一变量

需要通过 `IntegerAggregatorTest` 单元测试，以 `sum` 为例扼要解释一下测试逻辑：元组以第一列为分组依据，第二列求和，对 `(1,2)` 单行数据表本身就是结果，对  `(1,2),(1,4)` 两行数据表，返回一行结果 `(1,6)`；对 `(1,2),(1,4),(1,6)` 三行数据表，返回一行结果 `(1,12)`；对 `(1,2),(1,4),(1,6),(2,2)` 四行数据表，放回两行结果 `(1,12),(2,2)`。

还有具体实现类 `executor.StringAggregator`，同理实现那三个方法。并通过 `StringAggregatorTest` 单元测试。

需要实现 `executor.Aggregate` 类，同理用到了 `Operator` 接口。需要实现方法：

- `public Aggregate(OpIterator child, int afield, int gfield, Aggregator.Op aop)`
- `public int groupField()`
- `public String groupFieldName()`
- `public int aggregateField()`
- `public String aggregateFieldName()`
- `public Aggregator.Op aggregateOp()`
- `public static String nameOfAggregatorOp(Aggregator.Op aop)`
- `public void open()`
- `protected Tuple fetchNext()`
- `public void rewind()`
- `public TupleDesc getTupleDesc()`
- `public void close()`
- `public OpIterator[] getChildren()`
- `public void setChildren(OpIterator[] children)`

通过 `AggregateTest` 单元测试和 `AggregateTest` 系统测试

#### 具体实现

> 不妨复习一下 SQL group by，设有考生、成绩(科目列忽略)数据表：
>
> ```sql
> create table test (id int, score int);
> insert into test values (1, 100), (1,50), (1, 75), (2, 80), (2, 81), (4, 58);
> select id, sum(score), min(score), max(score), count(score), avg(score) from test group by id;
> select id, sum(score), min(score), max(score), count(score), avg(score) from test; -- NO_GROUPING
> ```
>
> 易得，可自行运行得到结果，由于篇幅这里不写出执行结果。第一个查询有三行结果，第二个查询只有一行结果。
>
> 能理解上述询问，则容易实现。

对 `IntegerAggregator`，可见，对上述操作符，对给定的 `int gbfield, Type gbfieldtype, int afield, Op what`，用 `afield` 列做聚合运算，所有 `gbfield` 相同的列分到一组去，同一组的列求聚合函数结果然后返回。如果 `NO_GROUPING`，则所有列同一组。

对各个操作，直接按照含义维护即可：

1. `MIN`。初始为 int 最大数，每传入一个 Tuple 取 `afield` 列对比保存更小者
2. `MAX`。与 MIN 相反，同理。
3. `SUM`。直接求和即可。
4. `AVG`。需要做整数下取整，所以需要维护求和及计数。
5. `COUNT`。直接计数即可。
6. `SUM_COUNT` 同 `COUNT`。
7. `SC_AVG`。同 `AVG`。

考虑一种优雅的实现，方便未来增加更多操作，不妨使用策略模式的思路，开一个抽象内部类维护 `ans` 成员的更新和取结果方法，然后设子类去实现。根据 what 的不同使用不同的子类。使用原型模式思想创建初始模板。

具体而言，做抽象内部类 `Result implements Cloneable`，提供 `protected int ans = 0` 和默认 `int get()`，重载 `public Object clone()`(这里不 throw, catch `super.clone()` 则 return null 即可)，留抽象方法 `public abstract void merge(int val)`。然后给五个子类去实现。且对 `ResultMin` 和 `ResultMax` 子类，构造函数重新赋值 `ans`，覆盖父类的默认赋值。对 `ResultAvg` 子类，加一个成员函数且重载覆盖 `get()`。

构造函数传进的四个值都同名存下来，开一个哈希表 `private HashMap<Field, Result> groups`，用于保留每组的结果。注意 null 可以做键，故 `NO_GROUPING` 也可特判。

开一个常量池 `private Result[] blanks`(可 static final)，按 `Op what` 的枚举顺序 new 七个对象。然后根据 `what.ordinal()` 取枚举下标，利用 `clone` 办法构造新的初始值。如果此哈希表键从未见过，则将复制的常量池对象作 merge 左值 self，然后新 Tuple 跟他合并后返回 put 回去覆盖哈希表项。即可完成 `mergeTupleIntoGroup()` 实现。

对 `iterator()` 实现，将哈希表转 `List<Tuple>`(注意要将 `Result` 构造成 `Tuple`)，然后调用写好的 `storage.TupleIterator` 类转迭代器即可。

> 因为 `gbfield != NO_GROUPING` 的 if else 写反了(写成 ==)导致手动写 main debug 了十多分钟。还有因为 List 忘记 add 错过，但很快发现了。

> 对 `StringAggregator`，使用本机 mysql8 测试如下数据：
>
> ```sql
> create table test (x int, y char(10));
> insert into test values (1, "abc"), (1, "f"), (1, "bbbbb"), (2, "lr580"), (2, "lr581"), (3, "baicha");
> select x, sum(y), min(y), max(y), count(y), avg(y) from test group by x;
> ```
>
> 发现 min, max 按字典序，且 sum, avg 直接返回 0，所以推断只需要实现三种运算。

因为只有 3 种有效运算符，这里直接朴素实现，而不用更利于修改的设计模式来做了。即只设计一个内部具体类 `Result` 即可。剩余逻辑仿照上面可以快速完成。注意字符串比较用 `.compareTo()`，注意 null 不可比较特判一下最开始。

对 `Aggregate`，其他方法 getter, setter 都很好处理。注意 `gfield` 为 `NO_GROUPING` 不能取 field 否则越界挂，需要直接返回 null。然后根据 `afield` 选择对应的 `Aggregator` 即可。注意 `getTupleDesc` 是结果的描述，这个有两种办法，一个是忽视 open, close 强行调用 `aggregator` 的取迭代器，用迭代器的 `TupleDesc`，但是复杂度差而且不优雅。所以这里考虑给接口 `Aggregator` 加一个 `getTupleDesc()` 接口，然后调整一下两个实现类，把取迭代器里获得 `TupleDesc` 的办法下延。

这里 `Aggregate` 必须要预先处理的思路，考虑仿照 `OrderBy` 的实现思路。因为结果必须要全部遍历完才能知道，显然，以 `NO_GROUPPING` 为例更加如此。从取迭代器的实现也可以看出。

> 记一个没通过系统测试的 `testAverageNoGroup()` 的 debug 过程。但是 debug 花了半个多小时大约，因为一开始没有顺着报错栈去找而是只看了报错文字没看地方先肉眼观察花了不少时间。
>
> 最终找到说 type 是空指针，追溯到是 int 取迭代器的取描述有误，原错误代码为：
>
> ```java
> TupleDesc td = new TupleDesc(new Type[] { gbfieldtype, Type.INT_TYPE });
> if (gbfield == NO_GROUPING) {
>     td = new TupleDesc(new Type[] { Type.INT_TYPE });
> }
> ```
>
> 当 `NO_GROUPING` 时，`gbfieldtype` 为 null，导致构造函数跑不通。正确是放到 else 里，不能偷懒省这点大括号：
>
> ```java
> TupleDesc td = null;
> if (gbfield == NO_GROUPING) {
>     td = new TupleDesc(new Type[] { Type.INT_TYPE });
> } else {
>     td = new TupleDesc(new Type[] { gbfieldtype, Type.INT_TYPE });
> }
> ```



### Exercise3

#### 任务要求

实现对 `HeapFile` 的增删 tuple。`Tuple` 有 `RecordID` 属性帮助找页。增删后对应的文件要产生变化。删修改头部。增就找到 empty slot，如无就加页，保证 `RecordID` 更新顺利。

对 `HeapPage`，要实现：

- `public void deleteTuple(Tuple t) throws DbException`
- `public void insertTuple(Tuple t) throws DbException`
- `public void markDirty(boolean dirty, TransactionId tid)` 若 true，事务 `tid` 将整页弄脏；否则，页面变回干净
- `public TransactionId isDirty()` 若脏页，返回最新弄脏该页的事务 ID，否则返回 null
- `private void markSlotUsed(int i, boolean value)`

需要通过 `HeapPageWriteTest` 单元测试，具体会测试事务直接弄脏和恢复干净页面；该页所有未用 slots 插入，然后页满再插入就报错；删除不存在的页报错；删掉存在的页面，删空报错。推测增删函数时不需要标脏，以单一职责原则。

对 `HeapFile`，要实现：

- `public List<Page> insertTuple(TransactionId tid, Tuple t) throws DbException, IOException, TransactionAbortedException`

- `public List<Page> deleteTuple(TransactionId tid, Tuple t) throws DbException, TransactionAbortedException`

  `insert, delete` 必须调用 `BufferPool.getPage()` 来访问页面，否则后续的 lab 做事务时会出错

- > `public void writePage(Page page) throws IOException`

对 `BufferPool`，要实现：

- ` public void insertTuple(TransactionId tid, int tableId, Tuple t) throws DbException, IOException, TransactionAbortedException`
- ` public void deleteTuple(TransactionId tid, int tableId, Tuple t) throws DbException, IOException, TransactionAbortedException`

#### 具体实现

先给 `Tuple` 补充 `RecordId` 的 getter, setter。具体而言是 `PageId` 和 `tupleNo` 的 POJO。并给 `Tuple` 重载一个 equals，只判断 fields 是否全都一样(`tupleDesc` 允许不同，如名字)。

修复一下上一节的 bug：

- `getNumUnusedSlots()` 使用了 `Integer.bitCount` 统计 1 的个数。然而 byte 全 1 时，值是 -1，隐式转 int 导致符号扩展而不是零扩展，所以导致统计出错。需要强转零扩展，使用 `Integer.bitCount(b & 0xff)`

对 `HeapPage`，与其他类关联度不大。直接先实现。脏就直接存事务即可，为 null 表示不脏。而 mark 就直接赋值即可，1 是有效 0 无效，做做位运算即可，与原本不一样的话该位取反。mark 方法可以用来搞后续的增删。

增删不需要具体写文件(所以脏了)，所以增直接改变成员变量即可，找到第一个空位数组赋值标 slot，给增的 tuple 加一个 `recordId`。删就遍历 tuples，看看有就删了，否则报错。
